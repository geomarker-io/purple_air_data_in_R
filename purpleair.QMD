---
title: "PurpleAir Data Exploration"
subtitle: "RISE Presentation"
author: "Stephen Colegate"
date: "July 9, 2023"
format:
  html:
    output-file: "index.html"
    embed-resources: true
toc: true
toc-expand: true
toc-title: Contents
editor: visual
bibliography: purpleair.bib
number-sections: true
number-depth: 2
---

# Introduction {#sec-intro}

Air quality sensors have the potential to provide high spatial and temporal resolution data and their accessibility in terms of cost and ease of use [@collier-oxandale2022]. Open access to environmental data sets and related tools is possible through a stable and consistent Application Programming Interface (API) that allows software and application developers to build applications to display and report that data in transparent and meaningful ways [@feenstra2020].

In this document, we will present methods of accessing synoptic and time series data using R software with the `AirSensor` package from the PurpleAir interface [@AirSensor]. We will then explore how to visualize both the spatial (in the form of maps) and temporal (in the form of time series plots) to determine air pollution trends.

## Basic Introduction to R and RStudio

[*NOTE*]{.underline}*: If you already are familiar with both R and RStudio, you may skip this section.*

R is a free, open-source software program that is available for Windows, Macs and Linux operating systems [@rcoreteam2013]. Because of this, many statisticians, biostatisticans, and data scientists have been using R to meet their data processing needs. In this tutorial, we will introduce how to install R and RStudio on your computer, try out basic R function commands, and learn how to install and load R packages. This foundation is necessary before we begin to read and explore PurpleAir sensor data.

### Installing R and RStudio {#sec-installR}

The latest version of R available as of the time of this writing is R-4.3.1. You can install R on your computer by going to <https://cran.r-project.org/> and selecting the R version that is appropriate for your operating system. Download the `base` distribution of R from the website and follow the prompts to install R on your computer.

After installing R on your computer, you will also need to install [RStudio Desktop](https://posit.co/download/rstudio-desktop/) - an integrated development environment (IDE) to help data scientists be more productive with R [@rstudioteam2020a]. RStudio is a dashboard hosted by [posit](https://posit.co/) that allows ease of access to using R, especially if you are using R for the first time. The posit website link should automatically direct you to the appropriate version of RStudio you will need to download and install on your computer. Once you have both R and RStudio installed, open up the RStudio software.

### Opening and Using R

Download the `purpleair.R` file from our [GitHub page](https://github.com/geomarker-io/purple_air_data_in_R). Make note of the file location on your computer where you save the file. It is recommended that you save the R file in a different location than your **Downloads** folder.

This kind of file is called an R script. You can identify R files with the file extension name `.R`. By default, RStudio should open a `.R` file if you click on it. If your computer does not recognize the `.R` file extension, you must tell your computer to open the file using RStudio. Optionally, you can also open an `.R` file within RStudio by following these steps:

1.  Open RStudio.
2.  Click on **File** \> **Open File**. A navigation window should appear.
3.  Navigate to the file location where you saved the `purpleair.R` file.
4.  Click **Open**.

A typical layout within RStudio has four different quadrants. Starting from the top-left clockwise:

1.  **Source Pane:** This panel displays all the R scripts you have opened. Code should be written in this panel. You can save R code within the panel to work on later. Any .R files you open with RStudio will be displayed in this panel.
2.  **Console Pane:** This panel displays the actual R console, including all the code and output that has been conducted so far.
3.  **Environment Pane:** This panel houses several tabs. The **Environment** tab lists all the R objects and variables available during the R session. The **History** tab keeps track of all code that has been executed in the Console. More tabs may be displayed depending on the type of project you may be working on.
4.  **Output Pane:** This panel includes a file viewer, plots that have been made, list of packages available and currently loaded, help documentation, a viewer, and a presentation tab.

R code is executed one line at a time. To run a line, place your cursor on the line you wish to run in the Source Pane and click on **Run**. The line of code is then sent to the Console Pane and is executed. You can highlight multiple lines of code and run them all at once as well. Optionally, you can run lines of code by using the shortcut **CTRL + ENTER**. To get started, here is some simple lines of code:

```{r example1}
# Assign values
x <- 2    # assign the letter 'x' the value 2
y <- 9    # assign the letter 'y' the value 9
```

[*NOTE:*]{.underline} *If the first line of code begins with the special character symbol `#`, then that line is called a comment. Comments are useful to write down what certain lines of code perform. R will not execute lines of code that begin with `#`. Likewise, R will not execute any code following the `#` symbol. As a result, the `#` symbol can also be used to grey out lines of code that maybe do not work or you wish to not execute without having to delete the entire line of code. In RStudio, comments are easily identified because the lines of code are written in green.*

Highlight the first line of code in the Source Pane `x <- 2`. The special character `<-` assigns the value provided on the right (`2`) to an object on the left (`x`). Hence, this line will set the variable `x` with the value of 2. The next line of code will assign the value `9` to the variable `y`. You can see that these values have been declared by clicking on the **Environment** tab in the Environment Pane.

With the variables `x` and `y` now declared, we can then use them to perform some simple operations:

```{r}
# Perform simple operations
x + y     # equivalent to '2' + '9'
sqrt(y)   # sqrt = square-root
```

Since `x` and `y` have been declared, R then calculates `x + y` and `sqrt(y)`. These results change depending on what the values of `x` and `y` are. As an exercise, change the values of `x` and `y` and rerun these lines again.

[*NOTE:*]{.underline} *Make sure you declare both `x` and `y` variables first before running `x + y` and `sqrt(y)` or else R will report an **ERROR** message.*

A rendered HTML of all the code and relevant output is hosted online on our GitHub page, which you can access by clicking [here](https://geomarker.io/purple_air_data_in_R/). All the R code that is available on this site is in the `purpleair.R` file. As you follow along on the site, try running all the available R code in the `purpleair.R` file to learn how to read in your PurpleAir data and do some basic data analysis with it.

<!--# Advanced users of R who are familiar with Quarto, a type of document that merges R code and output into a rendered document such as HTML or PDF output can check out the 'purpleair.QMD' and their associated files to study how this site is rendered. -->

### Packages {#sec-packages}

R packages are extensions to the base R environment, allowing the user to import data, functions, code, documentation and objects other creators have compiled. These packages are hosted on a centralized software repository such as the [Comprehensive R Archive Network (CRAN)](https://cran.r-project.org/).

#### Installing R Packages {#sec-packages-install}

Installing packages is easy and usually requires a one-time installation process. You will need to install the following packages in an R session in order to use the following code in this vignette:

-   [`dplyr`](https://cran.r-project.org/web/packages/dplyr/dplyr.pdf): a fast, consistent tool for working with data [@dplyr].

-   [`ggplot2`](https://cran.r-project.org/web/packages/ggplot2/ggplot2.pdf): a system for creating graphics [@ggplot2].

-   [`MazamaCoreUtils`](https://cran.r-project.org/web/packages/MazamaCoreUtils/MazamaCoreUtils.pdf): a suite of utility functions for working with AirSensor package [@MazamaCoreUtils].

-   [`MazamaSpatialUtils`](https://cran.r-project.org/web/packages/MazamaSpatialUtils/MazamaSpatialUtils.pdf): a suite of conversion function to return spatial polygon data [@MazamaSpatialUtils].

-   [`AirSensor`](https://github.com/MazamaScience/AirSensor): package for processing and displaying data from PurpleAir [@AirSensor].

To install these R packages, simply run the following code below.

[*NOTE*]{.underline}*: You may need to restart the R session in order for these packages to successfully install. If this is the case, select **Yes** when prompted to restart the R session. You may have to rerun the R code chunks again after restarting the session.*

```{r install_packages}
#| eval: false
# This only needs to be run once to install
install.packages('dplyr', 'ggplot2')

# Install the 'AirSensor' package
devtools::install_github("MazamaScience/AirSensor")
```

Some R package depend on other R packages (called **dependencies**). For example, compiling this Quarto document requires the knitr package for the rending to work. Packages that depend on other packages will install these extra packages automatically if they are not already installed in the users library. You can view all the R packages installed on your computer by clicking on the **Packages** tab in RStudio on the File Manager panel (bottom-right quadrant by default).

[*NOTE:*]{.underline} *R already comes with its own packages (e.g., datasets, graphics, etc.). You do not need to install these packages, as they are already preinstalled when R is first installed.*

Periodically, authors of R packages will update their package to fix bugs, add more functions and data sets, and to be better compatibble with the latest R software and other packages. You can use the `install.packages()` function to update (read re-install) the package to the latest version. By default, the latest version of the package available on CRAN will be installed.

#### Loading R Packages {#sec-packages-load}

Once R packages have been installed, you must then load the R package in the R environment. Loading in R packages allows the user to gain access to data, functions, and help documentation that comes along with the R package. To load an R package, use the function `library()` along with the package name.

```{r load_packages}
#| message: false
#| warning: false
# Load required R packages
library(dplyr)
library(ggplot2)
library(MazamaCoreUtils)
library(MazamaSpatialUtils)
library(AirSensor)
```

You can check whether a package is successfully loaded by clicking on the **Packages** tab in the File Manager quadrant. Loaded packages are indicated with a check mark. You can also load a package by selecting the open box next to the package name. Loaded packages can be unloaded by clicking on the check mark. Typically, however, packages are never unloaded, as functions that are part of a package will then become unavailable once the package is unloaded. All open packages are unloaded when R or RStudio is closed or a new R session begins.

[*NOTE*]{.underline}*: Unlike the installation process where the packages are installed only once, you must load these packages every time you start a new R session. When you quit your R session and start a fresh session, you must reload the R packages again.*

Sometimes, R will print a warning message if a package that is loaded could conflict with another package that is already loaded. This scenario appears if, for example, functions that share the same name but perform different actions from two or more packages. Functions from the latter package will mask functions that are included in packages loaded earlier by default. To use a masked function from an earlier package, you must either unload the latter package or reference specifically the package, as in the example below:

```{r package_ref}
# Pull example sensor data from the 'AirSensor' package
sen <- AirSensor::example_sensor

# Select only the data from the example sensor data
sen.data <- sen$data # $ - references 'data' column
```

[*NOTE:*]{.underline} *The `AirSensor` package does NOT have to be loaded for this code to work. Indeed, the `AirSensor::example_sensor` pulls the example_sensor data from the `AirSensor` package without loading the entire package. This is useful if you want to avoid loading in multiple packages that you many only use sparingly.*

The above R code chunk pulls the example_sensor data from the `AirSensor` without loading the package. The `$` operator is a special character in R. It references the column name within a data frame. In the example above, we want only the `data` column of the `example_sensor` data. We save only the sensor data in a data frame called sen.data. We can then display several first rows of this new R object with the `head()` function. By default, the first 6 rows are displayed. We can change this by declaring an **option** - additional arguments you can provide in an R function to modify its behavior. For example, the option `n=10` in the `head()` function changes the number of rows to display to 10:

```{r example_print}
# Display first n=10 rows of the example sensor data 
head(sen.data, n=10)
```

All options must be specified within a function. Each option is then followed by an `=` operator with the argument specified afterwards to pass onto the function. You will see more examples of using options later on.

# Synoptic Data {#sec-synoptic}

**Synoptic data** provides a synopsis - a comprehensive view of something at a moment in time. Synoptic data takes a snapshot of data from all the PurpleAir sensors at a moment in time and uploads them to the cloud. **Spatial data** utilizes synoptic data to visualize data in different spacial locations (such as across the United States) at a given moment. Spatial data from PurpleAir sensors are stored on the cloud as **PurpleAir Synoptic (PAS)** data.

This vignette demonstrates an example workflow for exploring air quality synoptic data using the AirSensor R package and data captured by the PurpleAir air quality sensors [@callahan_pas_2023]. Spatial data from PurpleAir will be downloaded from the PurpleAir API dashboard. We will then explore the spatial data by creating maps of air quality and temperature information.

## Loading PAS Data {#sec-loadingPAS}

There are two various was to obtaining PurpleAir Synoptic (PAS) data to use with this vignette. You can create a PAS object using the latest available PurpleAir sensor data from the PurpleAir website within your R environment. This method requires the user to create an account with PurpleAir and obtain an **Application Programming Interface (API)** key unique to the user to make specific queries. You can also pull an archived PAS object of historic PurpleAir data which accomplishes the same task.

### Live Source {#sec-live}

The [**PurpleAir API dashboard**](https://community.purpleair.com/t/new-api-dashboard/3981) allows users to create and manage their API keys and their usage. The site is available at [develop.purpleair.com](https://develop.purpleair.com/home). The dashboard requires a Gmail or Google-associated account to sign in.

#### Create a Project {#sec-createProject}

First create a project by following these steps:

1.  Sign in to [develop.purpleair.com](https://develop.purpleair.com/home) using a Gmail or Google-associated account.
2.  Click **Projects** on the left-hand side of the page.
3.  Click on **Add** in the top right-hand corner of the page.
4.  Enter in a project name.
5.  You must allocate points to your new project. New users begin with 1 million free points that they can allocate to any project. When an API query is executed in R, points will be deducted from this allocation based on the type of data being requested. Additional points may be purchased on the PurpleAir website. More information about how points are allocated and used can be found [here](https://community.purpleair.com/t/api-pricing/4523).
6.  Click **Add**.

Once a project has been created, you can then create an API key for that project.

#### Create API Key {#sec-createAPI}

To obtain your unique API key follow these steps:

1.  Sign in to [develop.purpleair.com](https://develop.purpleair.com/home) using a Gmail or Google-associated account.
2.  Click **API Keys** on the left-hand side of the page.
3.  Click on **Add** in the top right-hand corner of the page.
4.  You should see the auto-populated project name you created earlier (@sec-createProject). You can have several projects and API keys. Select the appropriate project if you have multiple projects.
5.  Select **Read** under "Type", select **Enabled** under "Status" , and leave all the other fields blank.
6.  Click **Add**.

You should then see your unique API key for the project. You can modify the allocation of points and examine the usage of the API key and its allocated points at any time.

[*NOTE*]{.underline}*: API keys are issued per user, not per sensor. Make sure that you have allocated points to the project associated with the API key before continuing on.*

#### Fetch and Set API Key {#sec-setAPI}

The API Key is an access token that allows you to pull PurpleAir sensor data from the cloud into your R session environment (see @sec-createAPI to learn how to create API Keys). It is not ideal to leave your API Key in a R script. If you share any of these documents that include your personal API Key with someone else, when they request PurpleAir sensor data, they will be using your points! A better solution is to save your API Key in a separate file that you keep and then provide code in the R script you are working worth that then looks for the file with your API Key and reads in the key.

In this example, suppose that the API Key for a given project is `a1b2c3d4e5f6g7h8i9j0` and the variable name to reference it is called `PurpleAir_API`.

1.  Create a new R script by clicking on **File** \> **New File** \> **R Script**.

2.  On the first line of this new blank R script, assign your PurpleAir API Key in quotes to a variable name you will then reference later. The `=` sign works just like the `<-` operator.

    ```{r global_vars}
    #| eval: false
    # Below is the first line of the 'global_vars.R' file
    PurpleAir_API = "a1b2c3d4e5f6g7h8i9j0"
    ```

    [*NOTE:*]{.underline} *Your PurpleAir API Key must be in single-quotes or double-quotes for this to work. API Keys are recognized in R as character strings. In RStudio, character strings are written in a forest green color to easily identify this.*

3.  Save this R file in the same folder as the R file you will use the API Key. In this example, we save the R file as `global_vars.R`. Once you have saved the R file that contains your API Key, you may then close the file.

4.  In the R script that you want to read in the API Key, use the `source()` function and then reference the R file (in this case, `global_vars.R`) that you saved in the previous step.

    ```{r set_API}
    #| eval: false
    # Read 'global_vars.R' file containing the API Key
    source(global_vars.R)
    ```

    [*NOTE:*]{.underline} *If you save your `global_vars.R` file in a different file location on your computer than the R script that you are using to pull the API Key from, you must specify the full file path in quotes in the `source()` function.*

5.  If done correctly, your current R session should fetch for the appropriate R file, read it, and then save your API Key as the variable name (in this case, `PurpleAir_API`) you specified in step 2. This is a great way to read in your API Key you have saved without having to specify it, protecting your access to the PurpleAir dashboard.

6.  Once you have read in the variable containing the API Key (in this case, `PurpleAir_API`), you must then define how you will use the API Key with the `setAPIKey()` function. To read in PurpleAir data, we must declare that our API Key will be used to read (not write) PurpleAir data:

    ```{r PurpleAir_red}
    #| eval: false
    # Set the API Key
    setAPIKey(provider = "PurpleAir-read", key = PurpleAir_API)
    ```

    ```{r}
    #| echo: false
    setAPIKey(provider = "PurpleAir-read", key = "a1b2c3d4e5f6g7h8i9j0")
    ```

7.  The first option `provider` specifies how we will use the API Key. The second option `key` identifies the API Key variable from the `global_vars.R` file.

8.  Verify that the API Key has been set correctly by running either the `getAPIKey()` function or the `showAPIKeys()` function:

    ```{r showAPIKeys}
    # Return all API Keys currently set
    showAPIKeys()
    ```

    This is a list of all the API Keys currently set in this R session. You can declare multiple API Keys if you have more than one project.

#### Create a New PAS Data Using API Key {#sec-createPAS}

PurpleAir sensor readings are uploaded to the cloud every 120 seconds. (Every 80 seconds prior to a May 31, 2019 firmware upgrade.) Data are processed by PurpleAir and a version of the data is displayed on the PurpleAir website.

You can generate a current PAS object by using the `pas_createNew()` function. A PAS object is large data frame with a record for each PurupleAir sensor channel (2 channels per sensor). The `pas_createNew()` function performs the following tasks under the hood:

1.  Download a raw dataset of the entire PurpleAir network that includes both metadata and recent PM2.5 averages for each deployed sensor across the globe. See `downloadParseSynopticData()` for more info.

2.  Subset and enhance the raw dataset by replacing variables with more consistent, human readable names and adding spatial metadata for each sensor including the nearest official air quality monitor. For a more in depth explanation, see `enhanceSynopticData()`.

To create a new PAS object you must first properly initialize the `MazamaSpatialUtils` package. This requires all the required R packages to be loaded into the R environment first (@sec-packages-load).

```{r initialize}
#| eval: false
# Initialization
initializeMazamaSpatialUtils()
```

The following example will create a brand new PAS object with up-to-the-minute data. Make sure you have set your unique API key (@sec-setAPI) before running this code below.

[*NOTE*]{.underline}*: You must have the appropriate number of points allocated to the API key in order for the PAS object to be created. If you do not have enough points on the API key, you will not be able to complete the operation.*

```{r pas_live}
#| eval: false
# Create new PAS object
pas_live <- pas_createNew(countryCodes="US",   # Country codes
                          stateCodes="OH",     # State codes
                          counties="Hamilton", # Counties
                          lookbackDays=7,      # Number of days to look back
                          location_type=NULL)  # 0 - outside; 1 - inside, NULL - both
```

[*NOTE*]{.underline}*: Creating a PAS object can take up to a minute to process.*

<!--# This section will be expanded upon later once we are familiar with using API Keys. -->

### Archive Source {#sec-archive}

It is also possible to load pre-generated PAS objects from a data archive specified by a URL in the `setArchiveBaseUrl()` function. Specify the name of the URL in quotes, as in the example below.

```{r setArchiveBaseUrl}
# Set location of pre-generated data files
setArchiveBaseUrl("https://airfire-data-exports.s3-us-west-2.amazonaws.com/PurpleAir/v1")
```

Archived PAS objects can be loaded very quickly with the `pas_load()` function, which obtains PAS objects from the archive specified with `setArchvieBaseUrl()`. When used without specifying the `datestamp` argument, `pas_load()` will obtain the most recently processed PAS object. But you can also use the `datestamp` argument inside `pas_load()` to load an archived PAS object from a specified date.

The following example loads a pre-generated PAS object from April 10, 2020 from the above archive base URL:

```{r pas_archive}
# Load a 'pas' object from a specific date
pas_apr10.2020 <- pas_load(datestamp="20200410")   # '20200410' = '4-10-2020'
```

## Exploring Spatial Data {#sec-PAS-explore}

[*NOTE*]{.underline}*: All the following R code chunks can be adapted to your own PAS object you create live (@sec-live) or archived (@sec-archive). For this demonstration, we will be using the example PAS from the `AirSensor` package to avoid long waiting times. This example PAS was generated on March 15, 2023 for outside sensors in California:*

```{r pas_example}
# Example PAS from AirSensor package
pas <- AirSensor::example_pas
```

*For more information about the example PAS, run the code below. This opens up a help documentation describing how this PAS is generated:*

```{r pas_help}
#| eval: false
# Open help documentation for example PAS
help(example_pas)
```

Take a look at the first 10 rows of the PAS data frame:

```{r pas_print}
# Examine the first 10 rows
print(pas, n=10, max_footer_lines=0)
```

There are `r nrow(pas)` columns and `r ncol(pas)` columns of the data frame. Not every column and row is displayed here. Each row of the PAS object corresponds to a unique PurpleAir sensor, identified by the `deviceDeploymentID` column, at this one moment in time. Each sensor records several columns of data, which we can take a look at below:

```{r pas_col}
# Get list of column names
names(pas)
```

At a glance, the PAS has several useful columns of data we can explore. There are column recordings of temperature, relative humidity, pressure, and air quality. We are interested in PM~2.5~ (particulate matter smaller than 2.5 micrometers in diameter). There are 6 columns related to PM~2.5~ measurements. These are average PM~2.5~ measurements taken by the sensor for a certain period of time. Notice how each column starts with the prefix `pm2.5`.

We can pull only those columns that begin with this prefix and store them as a new R object. Each row corresponds to one sensor so it is also a good idea to include the `locationID` of each sensor with our new `pm25` object. The code below takes the pas R object and then uses the `select()` function to choose `locationID` that starts with `pm2.5_` as the variable name (notice the use of quotes here!). The `%>%` operator is called a pipeline operator that is available in the `dplyr` package (and others) which can accomplish this process in one execution.

[*NOTE*]{.underline}*: The variable names of your PAS object may differ slightly from the examples provided here. Make sure you adapt the variable names such as `locationID` and `pm2.5_` exactly (case-sensitive, spelling, punctuation) so they match as specified in your PAS object.*

```{r pm25}
# Take a look at only PM2.5 data
pm25 <- pas %>%
  select(locationID, starts_with("pm2.5_"))
print(pm25, n=10)
```

Each row of this new `pm25_data` object corresponds to one PurpleAir sensor at a given location. Now that we have our PM~2.5~ data setup, we can now create maps to explore PM~2.5~ observations by location.

<!--# As of a recent 'knitr' update version 1.43, the leaflets are not rendering correctly in the HMTL output Quarto renders. There is a 'eval' option to turn off the leaflets if they do not display correctly or a ERROR message results when rendering the HTML output. To get them to render correctly, you must downgrade 'knitr' to version 1.42, shown below: -->

```{r}
#| eval: false
#| echo: false
# Remove latest version of 'knitr' package (if upgraded past 1.42)
remove.packages(knitr)

# Install 'knitr' package version 1.42
require(devtools)
install_version("knitr", version = 1.42)
```

Display a map of the 1-hour average PM~2.5~ measurement for each sensor:

```{r leaflet_pm25}
#| eval: true
# Plot interactive leaflet map of 1-hour average PM2.5
pas %>%
  pas_leaflet(parameter = "pm2.5_60minute")
```

A map is shown of all the sensors with their 1 hour average PM~2.5~ measurements. The icons represent one scanner, colored based on their measurement. Clicking on one of the icons brings up the device's ID, sensor index, location, temperature, humidity, and average PM~2.5~ measurements over a 1-hour and 24-hour period.

PAS data can consists of many sensors, resulting in many icons to select from in the map. We may wish to filter sensors based on their readings so that only those sensors who meet our filtering criteria appear on the map. This is useful, for example, if we are interested in identifying locations with high PM~2.5~ concentrations. The `pas_filter()` function can be used to filter sensors by state (with stateCode) and by a filtering criterion before it is passed to the `pas_leaflet()` function. In the example below, we identify PurpleAir sensors in California who register at least a 24-hour PM~2.5~ average of 12.0 micrograms per cubic meter - the equivalent of registering a Moderate [Air Quality Index (AQI)](https://www.epa.gov/sites/default/files/2016-04/documents/2012_aqi_factsheet.pdf):

```{r leaflet_filter}
#| eval: true
# Apply filtering of sensors
pas %>%
  pas_filter(stateCode == "CA", pm2.5_24hour > 12.0) %>%
  pas_leaflet(parameter = "pm2.5_24hour")
```

The PurpleAir sensors not only record PM~2.5~ data but they also record temperature and relative humidity as well. The following example displays the (high) temperature reading of all these sensors in California that are not missing:

```{r leaflet_temperature}
#| eval: true
# Plot interactive map of temperature, removing missing data
pas %>%
  pas_filter(stateCode == "CA", !is.na(temperature)) %>%
  pas_leaflet(parameter = "temperature")
```

It is left as an exercise to plot an interactive map of relative humidity observations for these same sensors.

# Time Series Data {#sec-timeseries}

**Time series** data provides a minute-by-minute database structure for transforming and analyzing [PurpleAir](https://www.purpleair.com/) sensor data. Unlike spatial data, which is geared for analyzing multiple sensors at one point in time, time series data focuses on a single PurpleAir sensor over time. In this manner, time series data allows the user to examine trends in air quality, temperature, and relative humidity recorded by one sensor.

In this section, we will demonstrate an example analysis of an individual monitor located in Seattle, Washington over a two-month duration in which the Pacific Northwest experienced [hazardous air-quality conditions](https://www.usnews.com/news/healthiest-communities/articles/2018-08-19/air-quality-to-worsen-in-northwest-as-smoke-returns) caused by wildfires in British Columbia, Canada [@callahan_pat_2023].

## Loading PAT Data {#sec-pat}

PurpleAir sensor readings are uploaded to the cloud every 120 seconds where they are stored for download and display on the PurpleAir website. After every interval, the synoptic data is refreshed and the outdated synoptic data is then stored in a [ThingSpeak](https://thingspeak.com) database. In order to access the ThingSpeak channel API we must first load the synoptic database, which was discussed in @sec-createPAS.

Once the PAS data frame has been loaded, we then create a **PurpleAir Time Series (PAT)** object by specifying the sensor and the dates from which to pull data from. Since this requires drawing data from the PurpleAir API dashboard, an API key (@sec-setAPI) is required to access this data to create the PAT object.

The following example will create a brand new PAT object with up-to-the-minute data. Assuming a PAS object has been loaded (@sec-createPAS), we use it to create the PAT object with a specific `sensor_index`. Make sure you have set your API Key (@sec-setAPI) before running this code below.

[*NOTE*]{.underline}*: You must have the appropriate number of points allocated to the API key in order for the PAT object to be created. If you do not have enough points on the API key, you will not be able to complete the operation.*

```{r pat}
#| eval: false
# Create new PAT object
pat <- pat_createNew(pas=pas,  # Your PAS object name
    sensor_index="3515",       # PurpleAir sensor ID
    startdate="2022-07-01",    # Start Date
    enddate="2022-07-08",      # End Date
    timezone="UTC",
    verbose=TRUE
  )
```

[*NOTE*]{.underline}*: Creating a PAT object can take up to a minute to process.*

<!--# This section will be expanded upon later once we are familiar with using API Keys. -->

## Exploring Temporal Data {#sec-PAT-explore}

[*NOTE*]{.underline}*: All the following R code chunks can be adapted to your own PAT object you create (@sec-pat). For this demonstration, we will be using the example PAT from the AirSensor package to avoid long waiting times. The example PAT was generated for a specific sensor in Seattle, Washington between July 1, 2022 and July 8, 2022.*

```{r pat_example}
# Example PAT from AirSensor package
pat <- AirSensor::example_pat
```

*For more information about the example PAT, run the code below. This opens up a help documentation describing how this PAT is generated:*

```{r pat_help}
#| eval: false
# Open help documentation for example PAT
help(example_pat)
```

Let's explore the PAT object:

```{r pat_names}
# Explore the PAT object
pat %>%
  names()
```

The PAT object contains two dataframes:

-   `meta` - Includes one row of data that does not change over time (e.g., device location, latitude, longitude, state, county, etc.)

    ```{r pat_meta}
    # Variables that do not change with time
    names(pat$meta)
    ```

-   `data` - Includes time series data that changes with time. Each row corresponds to a snapshot of data taken from sensor_index 3515 at a certain time (in UTC) and date.

    ```{r pat_data}
    # Examine time series data
    print(pat$data, n=10)
    ```

As you can see, the PurpleAir sensor takes frequent measurements of temperature, humidity, and air quality. As the PAT object shows, these measurements change over time. We can take a look at trends for all these measurements by plotting the time series for each variable:

```{r pat_multiplot}
# Plot raw sensor data
pat %>%
  pat_multiplot(plottype="all")
```

The `plottype` option allows the user to select which variable they are interested in seeing a time series of. For PM~2.5~, the measurements are taken by two different channels, labeled **channel A** and **channel B**. These channels record PM~2.5~ data. Notice a huge spike in PM~2.5~ in both channel B and especially channel A on the night of July 4. Why do you think PM~2.5~ levels spiked here?

PAT objects can span a wide range of dates. Suppose we are only interested in time series observations during the 4th of July weekend (July 2-4, 2022). We can create another PAT object from the original one by filtering out dates covering just these three dates:

```{r pat_filterDate}
# Filter dates from the PAT object
pat_fourth <- pat %>%
  pat_filterDate(startdate=20220702, enddate=20220705)
```

Our new PAT object, `pat_forth`, only covers dates between July 2, 2022 and July 4, 2022 (notice the `enddate` is July 5 since we want to include all the time points through July 4). Now let's take a look at only PM~2.5~ values more closely during this particular weekend:

```{r pat_pm25}
# Plot only PM2.5 data covering only the 4th of July weekend 2022
pat_fourth %>%
  pat_multiPlot(plottype = "pm25_over")
```

We can see noticeable peaks on the evening of Saturday, July 2, Sunday, July 3 and especially Monday, July 4. Channel A (red) only picks up the PM~2.5~ on the evening of July 4 whereas Channel B (blue) detects increased levels of PM~2.5~ every night throughout the 4th of July holiday.

How do the values of the PurpleAir sensor compare with those from a [federal monitor](https://tools.airfire.org/monitoring/v4#!/?category=PM2.5_nowcast&centerlat=42&centerlon=-95&zoom=4)? The `pat_externalFit()` function produces a linear model between data from the PurpleAir sensor and data from the closest federal monitor [@monitori].

```{r pat_externalFit}
#| warning: false
#| message: false
# Compare sensor data with hourly data from federal monitor
pat_fourth %>%
  pat_externalFit()
```

If the PurpleAir monitor readings agrees with that of the federal monitor, then we should expect to see a high correlation, or equivalently, a high R^2^ value associated with their readings. By comparing the observations made by the PurpleAir monitor to the federal monitor, we see very little difference in PM~2.5~ readings between the two. This gives us confidence that the PurpleAir monitor is recording its PM~2.5~ observations accurately.

The `AirSensor` package also has functions to evaluate the accuracy of the measurements made by the sensor. The `pat_outliers()` function will scan the PM~2.5~ observations and identify any measurements that are considered outliers:

```{r pat_outliers}
# Identify any outliers and replace them with window median values
pat_fourth_filter <- pat_fourth %>%
  pat_outliers(replace = TRUE, showPlot = TRUE)
```

The outliers, highlighted in red, are replaced instead with window median values. We can also check the accuracy of the PM~2.5~ measurements by comparing how the two channels record PM~2.5~ via the correlation of measurements taken between channel A and channel B using `pat_internalFit()`

```{r pat_internalFit}
# Compare Channel A and Channel B of the sensors
pat_fourth_filter %>%
  pat_internalFit()
```

A simple linear regression model fits the data from channel B to data from channel A. Ideally, we would like to see a strong negative correlation between temperature and humidity and a strong positive association between channel A and channel B.

```{r pat_scatterPlotMatrix}
#| message: false
#| warning: false
# Correlations to check that sensors are properly functioning
pat_fourth_filter %>%
  pat_scatterPlotMatrix()
```

While the correlation between temperature and humidity appears fine, the correlation between channel A and channel B is not as strong as we would like. This supports our observation of several inconsistent measurements especially on the evenings of July 2-4 between the two channels.

# Acknowledgements {#sec-thanks}

Special thanks to Dr. Cole Brokamp and Dr. Patrick Ryan for allowing me to speak at this workshop.

# References

::: {#refs}
:::
